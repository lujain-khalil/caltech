import argparse
import os
import json
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import subprocess
import sys
import time

# Local imports
import src.config as Config
from src.resnet_split import SplittableResNet18
from src.data_utils import get_dataloaders
from src.network_sim import NetworkSimulator

# ---------------------------
# TRAINING (CE ONLY)
# ---------------------------

def train_ce_model(dataset_name, device, epochs, batch_size, lr):
    """
    Train a vanilla SplittableResNet18 on the given dataset using CE loss only.
    Returns: trained model, training_history (list of dicts)
    """
    train_loader, _, num_classes, input_channels = get_dataloaders(
        dataset_name=dataset_name,
        batch_size=batch_size,
    )

    # Always 3-channel input due to your transforms
    model = SplittableResNet18(
        num_classes=num_classes,
        input_channels=input_channels,  # should be 3
        pretrained=True
    ).to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    history = []

    print(f"\n=== Training baseline model on {dataset_name.upper()} ===")
    for epoch in range(1, epochs + 1):
        print(f"Epoch {epoch:02d}/{epochs}...")
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)

            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, target)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * data.size(0)

            preds = outputs.argmax(dim=1)
            correct += preds.eq(target).sum().item()
            total += target.size(0)

        avg_loss = running_loss / total
        acc = 100.0 * correct / total
        print(f"Epoch {epoch:02d} | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%")

        history.append({
            "epoch": epoch,
            "train_loss": avg_loss,
            "train_acc": acc,
        })

    return model, history

# ---------------------------
# MAIN SCRIPT: LOOP 3 DATASETS
# ---------------------------

def main():
    parser = argparse.ArgumentParser(
        description="Baseline CE-only ResNet18 on MNIST/FMNIST/CIFAR10/CIFAR100 with edge vs cloud latency."
    )
    parser.add_argument("--dataset", type=str, default=None,
                        choices=["mnist", "fmnist", "cifar10", "cifar100"],
                        help="Specific dataset to train. If not specified, trains all datasets.")
    parser.add_argument("--epochs", type=int, default=Config.DEFAULT_EPOCHS)
    parser.add_argument("--batch_size", type=int, default=Config.DEFAULT_BATCH_SIZE)
    parser.add_argument("--lr", type=float, default=Config.DEFAULT_LR)

    parser.add_argument("--profile_file", type=str, default="latency_profile.json",
                        help="Latency profile JSON generated by profile_env.py")

    parser.add_argument("--bw_mbps", type=float, default=Config.DEFAULT_BW,
                        help="Average uplink bandwidth (for cloud-only comm).")
    parser.add_argument("--rtt_ms", type=float, default=Config.DEFAULT_RTT,
                        help="Average RTT (for cloud-only comm).")

    args = parser.parse_args()

    if not os.path.exists(args.profile_file):
        raise FileNotFoundError(
            f"{args.profile_file} not found. Run profile_env.py first to generate it."
        )

    with open(args.profile_file, "r") as f:
        profiles = json.load(f)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    net_sim = NetworkSimulator(avg_bw_mbps=args.bw_mbps, avg_rtt_ms=args.rtt_ms)

    # If specific dataset is provided, train only that; otherwise train all
    if args.dataset:
        datasets = [args.dataset]
    else:
        datasets = ["mnist", "fmnist", "cifar10", "cifar100"]

    base_dir = os.path.join("experiments", f"baseline_models")
    os.makedirs(base_dir, exist_ok=True)

    print(f"Saving baseline results under: {base_dir}")

    for ds in datasets:
        run_dir = os.path.join(base_dir, ds)
        os.makedirs(run_dir, exist_ok=True)

        # --- Train ---
        model, train_history = train_ce_model(
            dataset_name=ds,
            device=device,
            epochs=args.epochs,
            batch_size=args.batch_size,
            lr=args.lr,
        )

        # Save model
        model_path = os.path.join(run_dir, "model.pth")
        torch.save(model.state_dict(), model_path)

        # Save train log
        with open(os.path.join(run_dir, "train_log.json"), "w") as f:
            json.dump(train_history, f, indent=4)


if __name__ == "__main__":
    main()